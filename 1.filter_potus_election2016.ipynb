{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter posts on the reddit related to the 2016 U.S. presidential election\n",
    "\n",
    "python=3.7.16\n",
    "\n",
    "2016 POTUS Election（time：October 10 to December 19, 2016)\n",
    "\n",
    "All data sets analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from joblib import Parallel, delayed  # parallel computing\n",
    "from joblib import dump, load\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filter debunking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read the data sets one by one and append them together\n",
    "import glob  \n",
    "  \n",
    "# file path contains all the files of reddit comment data\n",
    "folder_path = '/mnt/data/wenlu/reddit-new/16-election-comment'  \n",
    "  \n",
    "# use glob library to find all the csv files\n",
    "csv_files = glob.glob(f'{folder_path}/*.csv')  \n",
    "  \n",
    "# empty DataFrame to save all the data\n",
    "all_data = pd.DataFrame()  \n",
    "\n",
    "for file in csv_files:  \n",
    "    df = pd.read_csv(file)  \n",
    "    all_data = all_data.append(df, ignore_index=True)  \n",
    "print(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 43s, sys: 44.3 s, total: 5min 28s\n",
      "Wall time: 5min 28s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>author</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>body</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>t5_3b66u</td>\n",
       "      <td>1.477958e+09</td>\n",
       "      <td>furry_irl</td>\n",
       "      <td>u/PM_ME_YIFF_PICS</td>\n",
       "      <td>d9g52fi</td>\n",
       "      <td>t1_d9fqrn9</td>\n",
       "      <td>yes I am</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>t5_2qh03</td>\n",
       "      <td>1.477958e+09</td>\n",
       "      <td>gaming</td>\n",
       "      <td>u/PhyrexStrike</td>\n",
       "      <td>d9g52fj</td>\n",
       "      <td>t1_d9ft6iq</td>\n",
       "      <td>[I definitely had flashbacks to that when that...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>t5_3hauq</td>\n",
       "      <td>1.477958e+09</td>\n",
       "      <td>ResearchSource</td>\n",
       "      <td>u/Psychonaut76</td>\n",
       "      <td>d9g52fk</td>\n",
       "      <td>t3_5aep3k</td>\n",
       "      <td>Nice review. How long from order to door was it?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>t5_2t1bl</td>\n",
       "      <td>1.477958e+09</td>\n",
       "      <td>Rainbow6</td>\n",
       "      <td>u/Oxi_</td>\n",
       "      <td>d9g52fl</td>\n",
       "      <td>t1_d9g1wcq</td>\n",
       "      <td>It's a fairly big issues lol, I made this post...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>t5_2uu0j</td>\n",
       "      <td>1.477958e+09</td>\n",
       "      <td>paragon</td>\n",
       "      <td>u/catdeuce</td>\n",
       "      <td>d9g52fm</td>\n",
       "      <td>t1_d9g45us</td>\n",
       "      <td>I have it.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78751994</th>\n",
       "      <td>71022314</td>\n",
       "      <td>t5_2qlqq</td>\n",
       "      <td>1.480550e+09</td>\n",
       "      <td>fantasyfootball</td>\n",
       "      <td>u/TheImmatureLawyer</td>\n",
       "      <td>damufh6</td>\n",
       "      <td>t1_damex80</td>\n",
       "      <td>You are right from a team perspective. But if ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78751995</th>\n",
       "      <td>71022315</td>\n",
       "      <td>t5_2ra29</td>\n",
       "      <td>1.480550e+09</td>\n",
       "      <td>buffalobills</td>\n",
       "      <td>u/ICookTheBlueStuff</td>\n",
       "      <td>damufh7</td>\n",
       "      <td>t1_damud1z</td>\n",
       "      <td>Missing the word: corner.\\n\\nYeah I dont see A...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78751996</th>\n",
       "      <td>71022316</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>1.480550e+09</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>u/jflb96</td>\n",
       "      <td>damufh8</td>\n",
       "      <td>t1_daml04y</td>\n",
       "      <td>But do it quick, because Outrageous_Claims' da...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78751997</th>\n",
       "      <td>71022317</td>\n",
       "      <td>t5_2t1bl</td>\n",
       "      <td>1.480550e+09</td>\n",
       "      <td>Rainbow6</td>\n",
       "      <td>u/andlkam2</td>\n",
       "      <td>damufh9</td>\n",
       "      <td>t3_5fqsmc</td>\n",
       "      <td>Poland's counter is Blitz.</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78751998</th>\n",
       "      <td>71022318</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>1.480550e+09</td>\n",
       "      <td>AskReddit</td>\n",
       "      <td>u/HarleySpencer</td>\n",
       "      <td>damufha</td>\n",
       "      <td>t3_5ft5gx</td>\n",
       "      <td>They think of me as a jungle gym and supplier ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72908588 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0 subreddit_id   created_utc        subreddit  \\\n",
       "0                 0     t5_3b66u  1.477958e+09        furry_irl   \n",
       "1                 1     t5_2qh03  1.477958e+09           gaming   \n",
       "2                 2     t5_3hauq  1.477958e+09   ResearchSource   \n",
       "3                 3     t5_2t1bl  1.477958e+09         Rainbow6   \n",
       "4                 4     t5_2uu0j  1.477958e+09          paragon   \n",
       "...             ...          ...           ...              ...   \n",
       "78751994   71022314     t5_2qlqq  1.480550e+09  fantasyfootball   \n",
       "78751995   71022315     t5_2ra29  1.480550e+09     buffalobills   \n",
       "78751996   71022316     t5_2qh1i  1.480550e+09        AskReddit   \n",
       "78751997   71022317     t5_2t1bl  1.480550e+09         Rainbow6   \n",
       "78751998   71022318     t5_2qh1i  1.480550e+09        AskReddit   \n",
       "\n",
       "                       author       id   parent_id  \\\n",
       "0           u/PM_ME_YIFF_PICS  d9g52fi  t1_d9fqrn9   \n",
       "1              u/PhyrexStrike  d9g52fj  t1_d9ft6iq   \n",
       "2              u/Psychonaut76  d9g52fk   t3_5aep3k   \n",
       "3                      u/Oxi_  d9g52fl  t1_d9g1wcq   \n",
       "4                  u/catdeuce  d9g52fm  t1_d9g45us   \n",
       "...                       ...      ...         ...   \n",
       "78751994  u/TheImmatureLawyer  damufh6  t1_damex80   \n",
       "78751995  u/ICookTheBlueStuff  damufh7  t1_damud1z   \n",
       "78751996             u/jflb96  damufh8  t1_daml04y   \n",
       "78751997           u/andlkam2  damufh9   t3_5fqsmc   \n",
       "78751998      u/HarleySpencer  damufha   t3_5ft5gx   \n",
       "\n",
       "                                                       body lang  \n",
       "0                                                 yes I am    tr  \n",
       "1         [I definitely had flashbacks to that when that...   en  \n",
       "2          Nice review. How long from order to door was it?   en  \n",
       "3         It's a fairly big issues lol, I made this post...   en  \n",
       "4                                                I have it.   en  \n",
       "...                                                     ...  ...  \n",
       "78751994  You are right from a team perspective. But if ...   en  \n",
       "78751995  Missing the word: corner.\\n\\nYeah I dont see A...   en  \n",
       "78751996  But do it quick, because Outrageous_Claims' da...   en  \n",
       "78751997                         Poland's counter is Blitz.   en  \n",
       "78751998  They think of me as a jungle gym and supplier ...   en  \n",
       "\n",
       "[72908588 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "#all_data = pd.read_csv('all_data_16election.csv')\n",
    "all_data.dropna(subset=['body'])  # drop the rows of 'body' columns containing NA / NaN value  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic & debunking keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# German\n",
    "keywords_German = [\"Trumpf\", \"Machen Sie Amerika wieder großartig\", \"Parlamentswahl 2016\", \"Amerika zuerst\", \"Hillary\", \"MachenSieAmerikawiedergroßartig\", \"Ich bin mit ihr zusammen\", \"Debatten2016\", \"Wahlen2016\", \"Clinton\"]\n",
    "\n",
    "# French\n",
    "keywords_French = [\"MAGA\", \"Rendre l'Amérique encore une fois formidable\", \"Trump\", \"L'Amérique d'abord\", \"Rendre sa grandeur à l’Amérique\", \"Hillary\", \"Clinton\", \"Je suis avec elle\", \"OHHillYes\",\"élection 2016\", \"élection 2016\", \"débats 2016\"]\n",
    "\n",
    "# topic key words filtering\n",
    "keywords_English = [\"MAGA\", \"MakeAmericaGreatAgain\", \"Trump\", \"AmericaFirst\", \"Make America Great Again\", \\\n",
    "             \"Hillary\", \"Clinton\", \"ImWithHer\", \"OHHillYes\", \\\n",
    "             \"election2016\", \"elections2016\", \"debates2016\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_df = pd.read_csv(\"/mnt/data/wenlu/new—program/data/(Merge_ver3)debunking_fact-checking_sites.csv\") # get the debunking media information\n",
    "db_df = db_df.dropna(subset=['domain'])\n",
    "db_df_domain = db_df['domain'].to_list()\n",
    "db_df_name = db_df['name'].to_list() # get more debunking key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add some Germany debunking media\n",
    "db_german_media = ['rumoursaboutgermany.info','faz.net', 'welt.de', 'correctiv.org','tagesschau.de/faktenfinder','zdf-investigativ','deutschlandfunk.de/']\n",
    "# topic key words filtering\n",
    "db_keywords_English = [\"fact check\", \"fact-checking\", \"fact checker\", \"fact checkers\", \"fake news\", \"misinformation\", \"disinformation\", \"debunkers\", \"debunker\", \"debunking\", \"debunking\", \"debunk\"]\n",
    "db_keywords_German = ['Faktencheck',\"Faktenprüfung\", \"Faktenprüfer\",\"faktenprüfer\", \"gefälschte Nachrichten\",\"Fehlinformation\", \"fehlinformation\",\"Desinformation\", \"desinformation\",\"Entlarver\", \"Entlarven\", \"entlarven\", \"entlarver\", \"entlarven\"]\n",
    "db_keywords_French = ['vérification des faits','fausses nouvelles','désinformation','fausse information','Réfuter les rumeurs','briseur de rumeur','discréditer']\n",
    "\n",
    "# add the debunk domain\n",
    "db_keyword_English_contains_domain = (keywords_English + db_df_domain + db_df_name)\n",
    "db_keyword_Ge_contains_domain = (db_keywords_German + db_df_domain + db_df_name + db_german_media)\n",
    "db_keyword_Fr_contains_domain = (db_keywords_French + db_df_domain + db_df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# English data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the dataframe\"all_data\" contains the language info(after langdetect)\n",
    "df_en = all_data[all_data['lang'] == 'en']\n",
    "df_en.to_csv('16election[lang=en][time=16.10-16.12].csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 59184212 entries, 1 to 78751998\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Unnamed: 0    object \n",
      " 1   subreddit_id  object \n",
      " 2   created_utc   float64\n",
      " 3   subreddit     object \n",
      " 4   author        object \n",
      " 5   id            object \n",
      " 6   parent_id     object \n",
      " 7   body          object \n",
      " 8   lang          object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 4.4+ GB\n"
     ]
    }
   ],
   "source": [
    "df_en.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27min 29s, sys: 7.51 s, total: 27min 36s\n",
      "Wall time: 27min 37s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['16-pkl/16election_[lang=en][time=16.10-16.12].pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df_en_topic_key = df_en[df_en['body'].str.contains('|'.join(keywords_English), case=False)]  # keywords searching in the body text\n",
    "df_en_topic_key.sort_index(axis=0, ascending=True, inplace=True)  # restore posting order\n",
    "df_en_topic_key.drop_duplicates(subset='id', keep='first', inplace=True)  # drop duplicates\n",
    "dump(df_en_topic_key,\"16-pkl/16election_[lang=en][time=16.10-16.12].pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2060294 entries, 24 to 78751988\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   Unnamed: 0    object \n",
      " 1   subreddit_id  object \n",
      " 2   created_utc   float64\n",
      " 3   subreddit     object \n",
      " 4   author        object \n",
      " 5   id            object \n",
      " 6   parent_id     object \n",
      " 7   body          object \n",
      " 8   lang          object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 157.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_en_topic_key.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15min 9s, sys: 890 ms, total: 15min 10s\n",
      "Wall time: 15min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['16-pkl/16election_debunk_[lang=en][time=16.10-16.12].pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# debunk keywords filt\n",
    "df_en_db_key = df_en_topic_key[df_en_topic_key['body'].str.contains('|'.join(db_keyword_English_contains_domain), case=False)]  # keywords searching in the body text\n",
    "df_en_db_key.sort_index(axis=0, ascending=True, inplace=True)  # Restore posting order\n",
    "df_en_db_key.drop_duplicates(subset='id', keep='first', inplace=True)  # drop duplicates\n",
    "dump(df_en_db_key,\"16-pkl/16election_debunk_[lang=en][time=16.10-16.12].pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30297 entries, 6793 to 78746321\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0    30297 non-null  object \n",
      " 1   subreddit_id  30297 non-null  object \n",
      " 2   created_utc   30297 non-null  float64\n",
      " 3   subreddit     30297 non-null  object \n",
      " 4   author        30297 non-null  object \n",
      " 5   id            30297 non-null  object \n",
      " 6   parent_id     30297 non-null  object \n",
      " 7   body          30297 non-null  object \n",
      " 8   lang          30297 non-null  object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_en_db_key.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## specific time filtering\n",
    "set time window to specific time eg.October 10 to December 19, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           1477958400\n",
       "1           1477958400\n",
       "2           1477958400\n",
       "3           1477958400\n",
       "4           1477958400\n",
       "               ...    \n",
       "71022314    1480550399\n",
       "71022315    1480550399\n",
       "71022316    1480550399\n",
       "71022317    1480550399\n",
       "71022318    1480550399\n",
       "Name: created_utc, Length: 71022319, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Oct. 10, 2016's utc timestamp:1476028801\n",
    "# Convert the string timestamp to an integer\n",
    "timestamp_oct_10_2016 = 1476028801\n",
    "\n",
    "# Boolean mask for filtering time\n",
    "mask = (all_data['created_utc'] >= timestamp_oct_10_2016)\n",
    "\n",
    "# Apply the mask to the DataFrame\n",
    "df_t = all_data[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 71022319 entries, 0 to 71022318\n",
      "Data columns (total 17 columns):\n",
      " #   Column                  Dtype \n",
      "---  ------                  ----- \n",
      " 0   subreddit_id            object\n",
      " 1   link_id                 object\n",
      " 2   created_utc             int64 \n",
      " 3   subreddit               object\n",
      " 4   retrieved_on            int64 \n",
      " 5   stickied                bool  \n",
      " 6   author_flair_text       object\n",
      " 7   score                   int64 \n",
      " 8   controversiality        int64 \n",
      " 9   author                  object\n",
      " 10  edited                  object\n",
      " 11  distinguished           object\n",
      " 12  id                      object\n",
      " 13  gilded                  int64 \n",
      " 14  author_flair_css_class  object\n",
      " 15  parent_id               object\n",
      " 16  body                    object\n",
      "dtypes: bool(1), int64(5), object(11)\n",
      "memory usage: 9.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df_t.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_t = df_t.sort_values(by='created_utc').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_t.to_csv('new_16election_reddit_comment[time=16.10.10-16.12.31].csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
